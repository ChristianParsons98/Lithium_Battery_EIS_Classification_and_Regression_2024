{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5669f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from scipy.stats import linregress\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eeca584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start by getting the list of freuencies that EIS is measured at.\n",
    "#Create a list of column names that we will transform the data to. \n",
    "df_forCols=pd.read_csv('./Data/Lithium/EIS_data/EIS_state_I_25C01.txt', sep='\\t')\n",
    "f_vals=df_forCols['freq/Hz'][:60].tolist()\n",
    "#Col_names will be my new column labels\n",
    "Col_names_Re = []\n",
    "Col_names_Im = []\n",
    "\n",
    "for freq in f_vals:\n",
    "    Re_str = str(freq)+' Re'\n",
    "    Im_str = str(freq)+' Im'\n",
    "    Col_names_Re.append(Re_str)\n",
    "    Col_names_Im.append(Im_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42419dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure Cycle not Reached for 25C04 Slope Method Used.\n"
     ]
    }
   ],
   "source": [
    "###### Cleans the Capacity Data.  ######\n",
    "##Generating the Capacity dataframe for use below. \n",
    "\n",
    "# Get txt files list from EIS folder\n",
    "path = './Data/Lithium/Capacity_data'\n",
    "txt_files = glob.glob(path + \"/*.txt\")\n",
    "#Generate a list of the individual dataframes\n",
    "df_list_Cap=[]\n",
    "for file in txt_files:\n",
    "    fname= file.split('Data_Capacity_')[-1][:-4]\n",
    "    df_1 = pd.read_csv(file, sep='\\t')\n",
    "    df_2 = pd.concat([df_1['time/s'],df_1['cycle number'],df_1['ox/red'],df_1['Capacity/mA.h']],axis=1)\n",
    "    #Adding a label column with a value based on the file name\n",
    "    df_2['label']=str(fname)\n",
    "    df_list_Cap.append(df_2)\n",
    "\n",
    "#Concatenate all of the dataframes together into one large dataframe\n",
    "df_Cap=df_list_Cap[0]\n",
    "for i in range(1,len(df_list_Cap)):\n",
    "    df_Cap= pd.concat([df_Cap, df_list_Cap[i]], axis=0, ignore_index=True)\n",
    "\n",
    "#Check if their published data is only for 0??\n",
    "sub_df=df_Cap[(df_Cap['ox/red']==0)]\n",
    "#Generates the dataframe with the max capacity for each label and cycle number.\n",
    "grouped_data = sub_df.groupby(['label','cycle number'])\n",
    "max_Cap_grouped = grouped_data['Capacity/mA.h'].max()\n",
    "max_Cap_grouped = max_Cap_grouped.reset_index()\n",
    "#max_Cap_grouped.shape\n",
    "\n",
    "#Normalize capacity based on first cycle for each label.\n",
    "df = max_Cap_grouped[['label','cycle number','Capacity/mA.h']]\n",
    "\n",
    "#rename cycle 0 in capacity data to cycle 1 so that there is a 1-1 correspondance in EIS data.\n",
    "df['cycle number']=df['cycle number'].apply(lambda x: int(x + 1.))\n",
    "U_labels = list(df['label'].unique())\n",
    "norm_df=pd.DataFrame(columns=['label','cycle number','Capacity/mA.h','Norm_Cap'])\n",
    "for label in U_labels:\n",
    "    try:\n",
    "        selected_rows = df[(df['label'] == label)]\n",
    "        Cap1=selected_rows.iloc[0]['Capacity/mA.h']\n",
    "        normalizedCap=selected_rows['Capacity/mA.h'].apply(lambda x: x/Cap1)\n",
    "        normalizedCap=normalizedCap.rename('Norm_Cap')     \n",
    "        tempdf = selected_rows.merge(normalizedCap,left_index=True, right_index=True)  \n",
    "        norm_df = pd.concat([norm_df,tempdf],ignore_index=True)    \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "#Generate Cycles to Fail Column and add it to the dataframe\n",
    "U_labels = list(norm_df['label'].unique())\n",
    "CtF_df=pd.DataFrame(columns=['label','cycle number','Capacity/mA.h','Norm_Cap','Cycles Until Fail'])\n",
    "for label in U_labels:\n",
    "    selected_rows = norm_df[(norm_df['label'] == label)]\n",
    "    failed_rows = selected_rows[selected_rows['Norm_Cap']<=0.8]\n",
    "    if len(failed_rows)==0:\n",
    "        print('Failure Cycle not Reached for',label,'Slope Method Used.')\n",
    "        #if the battery does not reach the failure point of 0.8, we have to extrapolate\n",
    "        #For some of the data, linregress gives an extrapolated value which is much too high\n",
    "        #These batteries with extrapolated failure points should not be used to train regression. \n",
    "        y=selected_rows['Norm_Cap'].to_numpy()\n",
    "        x=selected_rows['cycle number'].to_numpy()\n",
    "        x = x[:].astype(np.float32)\n",
    "        #slope does a linear regression on the full set of x,y data points.\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "        Fail_C = (.8-intercept)/slope        \n",
    "\n",
    "\n",
    "    else:\n",
    "        Fail_C=failed_rows.iloc[0]['cycle number']\n",
    "    \n",
    "    Fail_C = int(Fail_C)\n",
    "    cyc_toFail=selected_rows['cycle number'].apply(lambda x: Fail_C-x)\n",
    "    cyc_toFail=cyc_toFail.rename('Cycles Until Fail')     \n",
    "    tempdf = selected_rows.merge(cyc_toFail,left_index=True, right_index=True)  \n",
    "    CtF_df = pd.concat([CtF_df,tempdf],ignore_index=True)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1728bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e29da796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at I 25C05  cycle:   329.00000\n",
      "Missing EIS Frequencies in Data for this cycle.\n",
      "Finished with I\n",
      "(2741, 127)\n",
      "Finished with II\n",
      "(2600, 127)\n",
      "Finished with III\n",
      "(2599, 127)\n",
      "Error at IV 25C05  cycle:   276.00000\n",
      "Missing EIS Frequencies in Data for this cycle.\n",
      "Finished with IV\n",
      "(2597, 127)\n",
      "Finished with V\n",
      "(2597, 127)\n",
      "Finished with VI\n",
      "(1308, 127)\n",
      "Finished with VII\n",
      "(424, 127)\n",
      "Finished with VIII\n",
      "(424, 127)\n",
      "Finished with IX\n",
      "(2737, 127)\n"
     ]
    }
   ],
   "source": [
    "###### Cleans the data and creates set of EIS and PCA csv's for each state of charge.  ######\n",
    "\n",
    "#Create new folder for the cleaned data if it does not already exist.\n",
    "if not os.path.exists('./Cleaned_Data'):\n",
    "    os.makedirs('./Cleaned_Data')\n",
    "\n",
    "#List of all of the named state of charges.\n",
    "SoC_lst = ['I','II','III','IV','V','VI','VII','VIII','IX']\n",
    "\n",
    "# Get txt files list from EIS folder\n",
    "path = './Data/Lithium/EIS_data'\n",
    "txt_files = glob.glob(path + \"/*.txt\")\n",
    "\n",
    "for SoC in SoC_lst:\n",
    "    SoC_files = []\n",
    "    for files in txt_files:\n",
    "        if str('_'+SoC+'_') in files:\n",
    "            SoC_files.append(files)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    #Generate a list of the individual dataframes\n",
    "    df_list=[]\n",
    "    for file in SoC_files:\n",
    "        fname= file.split(str('EIS_state_'+SoC+'_'))[-1][:-4]\n",
    "        #The published data has headers for some data files. Other have no header. Need to check. \n",
    "        df_temp=pd.read_csv(file, sep='\\t',header=None)\n",
    "        #if statement to remove the first row if it was a header. The check is if the first character is t (time)\n",
    "        if str(df_temp.iloc[0][0])[0]=='t':\n",
    "            df_temp = df_temp[1:]\n",
    "        else:\n",
    "            pass\n",
    "        #Adding this line because the labels have random spaces in front or after. Standardizing column names.\n",
    "        df_temp.columns = ['time/s', 'cycle number', 'freq/Hz', 'Re(Z)/Ohm', '-Im(Z)/Ohm', '|Z|/Ohm', 'Phase(Z)/deg']\n",
    "        #Adding a label column with a value based on the file name\n",
    "        df_temp['label']=str(fname)\n",
    "        df_list.append(df_temp)\n",
    "\n",
    "    #Concatenate all of the dataframes together into one large dataframe\n",
    "    df_EIS=df_list[0]\n",
    "    for i in range(1,len(df_list)):\n",
    "        df_EIS= pd.concat([df_EIS, df_list[i]], axis=0, ignore_index=True)\n",
    "        \n",
    "\n",
    "    Col_names = ['label','cycle number']+Col_names_Re+Col_names_Im\n",
    "    \n",
    "    \n",
    "    U_labels = list(df_EIS['label'].unique())\n",
    "    U_cycles = list(df_EIS['cycle number'].unique())\n",
    "\n",
    "    #Here I am changing the format of the dataframe so that each impedance response at each frequency has its own column\n",
    "    U_labels = list(df_EIS['label'].unique())\n",
    "    #U_cycles = list(df_EIS['cycle number'].unique())\n",
    "    sq_df=pd.DataFrame(columns=Col_names)\n",
    "    for label in U_labels:\n",
    "        label_df = df_EIS[(df_EIS['label'] == label)]\n",
    "        U_cycles = list(label_df['cycle number'].unique())\n",
    "        for cycle in U_cycles:\n",
    "            try:\n",
    "                selected_rows = label_df[(label_df['cycle number'] == cycle)]\n",
    "                Re_data=selected_rows['Re(Z)/Ohm'].tolist()\n",
    "                Im_data=selected_rows['-Im(Z)/Ohm'].tolist()\n",
    "                Imp_data=[label,int(float(cycle))]+Re_data+Im_data\n",
    "                sq_df.loc[len(sq_df.index)] = Imp_data \n",
    "            except:\n",
    "                print('Error at',SoC,label,' cycle: ',cycle)\n",
    "                if not len(Imp_data)==122:\n",
    "                    print('Missing EIS Frequencies in Data for this cycle.')\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "            \n",
    "    #Take only the data where there is overlap with the capacity data. \n",
    "    new_df2 = CtF_df.merge(sq_df,on=['label','cycle number'],how='inner')\n",
    "    \n",
    "    #Get the EIS part of the df only so that we can do PCA.\n",
    "    EIS_Only_df = new_df2.drop(['label','cycle number','Capacity/mA.h','Norm_Cap','Cycles Until Fail'],axis=1)\n",
    "    \n",
    "    #Define the PCA \n",
    "    #We do not need to use a standard scalar here - all are measurements of impedance response.\n",
    "    #Take only the two most important dimensions\n",
    "    pca = PCA(2)\n",
    "    #Perform the PCA fit and transform the features into that reduced dimensional space\n",
    "    \n",
    "    principalComponents = pca.fit_transform(EIS_Only_df)\n",
    "\n",
    "    #Put it into a pandas df\n",
    "    Reduced_df = pd.DataFrame(data = principalComponents)\n",
    "    Reduced_df.columns =['EIS_PCA_1','EIS_PCA_2']\n",
    "    \n",
    "    Full_df = new_df2.join(Reduced_df)\n",
    "    Full_df.to_csv(str('./Cleaned_Data/'+SoC+'_Full_Data_wPCA.csv'),index=False)\n",
    "    \n",
    "    print(str('Finished with '+SoC))\n",
    "    print(Full_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a27dcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
